{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01baefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"./dataset_public.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91753a",
   "metadata": {},
   "source": [
    "We need to set some constants for the experiment: \n",
    "- the search budget $B$ (how many configurations is the optimizer allowed to evaluate), \n",
    "- the number of production runs $N$ (how many times will we run the batch workload between subsequent runs of the optimizer), \n",
    "- the optimization target (what metric do we want to minimize: `cost` or `runtime`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8425f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 33  # search budget\n",
    "N = 64  # number of production runs\n",
    "opt_target = 'cost'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628502a",
   "metadata": {},
   "source": [
    "When we want to evaluate a cloud configuration for a specific workload, we run `calculate_objective()`, which, for a given dictionary `config`, returns the average value of the optimization target of interest `target`.\n",
    "- Note that some workloads have been evaluated on some configurations **more than once** - that is why we calculate the average of all found entries.\n",
    "- Additionally, some workloads with some configurations have **never** been evaluated due to the quotas imposed by some cloud providers - in such cases, the function returns `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f54261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective(workload, config, target):\n",
    "    data_w = data[data['workload']==workload]\n",
    "    matching_entries = data_w.loc[(data_w[list(config)] == pd.Series(config)).all(axis=1)]\n",
    "    objective_value = matching_entries['target_%s' % (target)].mean()\n",
    "    return objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baba4f5",
   "metadata": {},
   "source": [
    "After the optimizer has finished the search and has suggested a cloud provider and configuration, we calculate 2 metrics to evaluate the quality of the optimizer's results: regret and savings.\n",
    "\n",
    "**Regret** expresses the relative percentage difference between the values $f$ of the optimization target for the suggested configuration and for the actually best configuration within the domain:\n",
    "\n",
    "$Regret = 100 \\cdot \\frac{f_{found} - f_{best}}{f_{best}}$\n",
    "\n",
    "**Savings** measure the difference between the total expenses of running the optimizer and of using a random configuration. The expense in this case can be understood as the total monetary cost or runtime, depending on the used optimization target. The savings metric is supposed to evaluate whether the savings achieved by using the optimized configuration makes up for the additional cost of running the optimizer itself. When a **random configuration** is used, the only expense results from $N$ production runs of the workload, each time with the expense $R_{random}$. When we used an **optimized configuration**, there is an additional expense $C_{opt}$ of running the optimizer, which is then followed by $N$ production runs of the workload using the optimized configuration, each time with the expense $R_{opt}$.\n",
    "\n",
    "$Savings = 100 \\cdot \\frac{N \\cdot R_{random} - (C_{opt} + N \\cdot R_{opt})}{N \\cdot R_{random}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac239064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(workload, target, opt_result, opt_expense, n_prod_runs):\n",
    "    data_w = data[data['workload']==workload]\n",
    "    true_min = data_w['target_%s' % (target)].min()\n",
    "    avg_result = data_w['target_%s' % (target)].mean()\n",
    "\n",
    "    regret = 100 * (opt_result - true_min) / true_min\n",
    "    savings = 100 * ((n_prod_runs * avg_result) - (opt_expense + n_prod_runs * opt_result)) / (n_prod_runs * avg_result)\n",
    "    \n",
    "    return regret, savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec969ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average regret: 25.748349703115505\n",
      "Average savings: 34.40530063796556\n"
     ]
    }
   ],
   "source": [
    "all_regrets = []\n",
    "all_savings = []\n",
    "for workload in data['workload'].unique():\n",
    "\n",
    "    # Perform Random Search\n",
    "    best_objective = np.inf\n",
    "    optimization_expense = 0\n",
    "    evals_made = 0\n",
    "    np.random.seed(42)\n",
    "    while evals_made < B:\n",
    "        # Choose a new point\n",
    "        new_point = {}\n",
    "        provider = np.random.choice(data['provider'].unique())\n",
    "        for feature in data.columns:\n",
    "            if provider in feature or feature in ['nodes']:\n",
    "                feature_values = [val for val in data[feature].dropna().unique() if val is not None]\n",
    "                feature_value = np.random.choice(feature_values)\n",
    "                new_point[feature] = feature_value\n",
    "\n",
    "        # Evaluate\n",
    "        new_objective = calculate_objective(workload=workload,\n",
    "                                            config=new_point, \n",
    "                                            target=opt_target)\n",
    "        if np.isnan(new_objective):\n",
    "            continue\n",
    "        optimization_expense += new_objective\n",
    "        best_objective = min(best_objective, new_objective)\n",
    "        evals_made += 1\n",
    "    \n",
    "    regret, savings = calculate_results(workload=workload,\n",
    "                                        target=opt_target,\n",
    "                                        opt_result=best_objective,\n",
    "                                        opt_expense=optimization_expense,\n",
    "                                        n_prod_runs=N)\n",
    "    all_regrets.append(regret)\n",
    "    all_savings.append(savings)\n",
    "\n",
    "print(\"Average regret:\", np.mean(all_regrets))\n",
    "print(\"Average savings:\", np.mean(all_savings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
